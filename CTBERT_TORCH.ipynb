{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "WNUT_CTBERT_TORCH.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "qw41gWikJ3eA",
        "outputId": "ff981181-5573-4a0d-d313-d7bc3bce3767",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "! git clone https://github.com/VinAIResearch/COVID19Tweet.git\n",
        "! pip install transformers\n",
        "\n",
        "import numpy as np \n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "\n",
        "train_df = pd.read_csv(\"COVID19Tweet/train.tsv\", sep='\\t')\n",
        "val_df = pd.read_csv(\"COVID19Tweet/valid.tsv\", sep='\\t',names=['Id','Text','Label'])\n",
        "test_df = pd.read_csv(\"COVID19Tweet/unlabeled_test_with_noise.tsv\", sep='\\t',names=['Id','Text'])\n",
        "\n",
        "train_sentences = train_df.Text.values\n",
        "train_labels =  train_df.Label.values\n",
        "\n",
        "val_sentences = val_df.Text.values\n",
        "val_labels =  val_df.Label.values\n",
        "\n",
        "\n",
        "test_sentences = test_df.Text.values\n",
        "# test_labels =  val_df.Label.values\n",
        "\n",
        "y_train = [int(label == 'INFORMATIVE') for label in train_labels]\n",
        "y_val = [int(label == 'INFORMATIVE') for label in val_labels]\n",
        "\n",
        "y_train = np.array(y_train)\n",
        "y_val = np.array(y_val)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'COVID19Tweet' already exists and is not an empty directory.\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (3.1.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n",
            "Requirement already satisfied: tokenizers==0.8.1.rc2 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8.1rc2)\n",
            "Requirement already satisfied: sentencepiece!=0.1.92 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.91)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.16.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gl1YdGHU1F_4"
      },
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification,  AdamW\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"digitalepidemiologylab/covid-twitter-bert\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "avEpISlhMzHX"
      },
      "source": [
        "model = AutoModelForSequenceClassification.from_pretrained(\"digitalepidemiologylab/covid-twitter-bert\" ,\n",
        "                                                                       num_labels = 2, # The number of output labels--2 for binary classification.\n",
        "    output_attentions = False, # Whether the model returns attentions weights.\n",
        "    output_hidden_states = False).cuda()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l9kQr92vrLs3"
      },
      "source": [
        "learning_rate = 2e-5\n",
        "max_length = 128\n",
        "batch_size = 16\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHOzwFwirbou"
      },
      "source": [
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = learning_rate, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "                )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EzIAgsZTXLRw"
      },
      "source": [
        "import logging\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "\n",
        "logging.getLogger('transformers').setLevel(logging.ERROR)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mJFcVE9ODV_k"
      },
      "source": [
        "# training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GVkAZTPC684e",
        "outputId": "8d2482f9-1d07-49f5-863b-0160029a2626",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# number of epochs\n",
        "Epochs = 5\n",
        "\n",
        "for i in range(Epochs):\n",
        "  print(\"-------------------------------------------------------\")\n",
        "  print('Epoch ', i)\n",
        "\n",
        "  model.train()\n",
        "  training_steps = int(len(train_sentences)/batch_size)+1\n",
        "  losses = []\n",
        "  # 1 epoch over X_train\n",
        "  with tqdm(total=training_steps) as progress_bar:\n",
        "    for i in range(0, len(train_sentences), batch_size):\n",
        "      batch_X = train_sentences[i:i+batch_size]\n",
        "      batch_y = torch.LongTensor(y_train[i:i+batch_size]).cuda()\n",
        "\n",
        "\n",
        "      encoding = tokenizer(list(batch_X),padding='max_length',truncation=\"longest_first\", max_length  = max_length,return_tensors='pt')\n",
        "      input_ids = encoding['input_ids'].cuda()\n",
        "      attention_mask = encoding['attention_mask'].cuda()\n",
        "      token_type_ids = encoding['token_type_ids'].cuda()\n",
        "\n",
        "      loss, logits = model(input_ids= input_ids,attention_mask=attention_mask, token_type_ids=token_type_ids,labels=batch_y)\n",
        "\n",
        "\n",
        "      torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      model.zero_grad()\n",
        "\n",
        "      losses.append(loss.item())\n",
        "      avg_loss = sum(losses)/len(losses)\n",
        "      progress_bar.update(1)\n",
        "      progress_bar.set_description(\"avg loss so far = {}\".format(avg_loss))\n",
        "\n",
        "  model.eval()\n",
        "  eval_steps = int(len(val_sentences)/batch_size)+1\n",
        "  list_of_logits = []\n",
        "\n",
        "  with tqdm(total=eval_steps) as progress_bar:\n",
        "    for i in range(0, len(val_sentences), batch_size):\n",
        "      batch_X = val_sentences[i:i+batch_size]\n",
        "\n",
        "\n",
        "\n",
        "      encoding = tokenizer(list(batch_X),padding='max_length',truncation=\"longest_first\", max_length  = max_length,return_tensors='pt')\n",
        "      input_ids = encoding['input_ids'].cuda()\n",
        "      attention_mask = encoding['attention_mask'].cuda()\n",
        "      token_type_ids = encoding['token_type_ids'].cuda()\n",
        "\n",
        "      logits = model(input_ids= input_ids,attention_mask=attention_mask, token_type_ids=token_type_ids)[0]\n",
        "      list_of_logits.extend(logits.tolist())\n",
        "\n",
        "      progress_bar.update(1)\n",
        "      \n",
        "  preds_bert = np.argmax(list_of_logits,axis=1)\n",
        "  print()\n",
        "  print(classification_report(y_val, preds_bert,digits=6))\n",
        "\n",
        "  print(\"-------------------------------------------------------\")\n",
        "  print(\"-------------------------------------------------------\")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/434 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "-------------------------------------------------------\n",
            "Epoch  0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "avg loss so far = 0.16066371720855036: 100%|██████████| 434/434 [08:43<00:00,  1.21s/it]\n",
            "100%|██████████| 63/63 [00:25<00:00,  2.49it/s]\n",
            "  0%|          | 0/434 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0   0.935547  0.907197  0.921154       528\n",
            "           1   0.899590  0.930085  0.914583       472\n",
            "\n",
            "    accuracy                       0.918000      1000\n",
            "   macro avg   0.917569  0.918641  0.917869      1000\n",
            "weighted avg   0.918575  0.918000  0.918053      1000\n",
            "\n",
            "-------------------------------------------------------\n",
            "-------------------------------------------------------\n",
            "-------------------------------------------------------\n",
            "Epoch  1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "avg loss so far = 0.0410802869838641: 100%|██████████| 434/434 [08:42<00:00,  1.20s/it]\n",
            "100%|██████████| 63/63 [00:25<00:00,  2.49it/s]\n",
            "  0%|          | 0/434 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0   0.893116  0.933712  0.912963       528\n",
            "           1   0.921875  0.875000  0.897826       472\n",
            "\n",
            "    accuracy                       0.906000      1000\n",
            "   macro avg   0.907495  0.904356  0.905395      1000\n",
            "weighted avg   0.906690  0.906000  0.905818      1000\n",
            "\n",
            "-------------------------------------------------------\n",
            "-------------------------------------------------------\n",
            "-------------------------------------------------------\n",
            "Epoch  2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "avg loss so far = 0.02025820579876574: 100%|██████████| 434/434 [08:42<00:00,  1.20s/it]\n",
            "100%|██████████| 63/63 [00:25<00:00,  2.48it/s]\n",
            "  0%|          | 0/434 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0   0.914019  0.926136  0.920038       528\n",
            "           1   0.916129  0.902542  0.909285       472\n",
            "\n",
            "    accuracy                       0.915000      1000\n",
            "   macro avg   0.915074  0.914339  0.914661      1000\n",
            "weighted avg   0.915015  0.915000  0.914962      1000\n",
            "\n",
            "-------------------------------------------------------\n",
            "-------------------------------------------------------\n",
            "-------------------------------------------------------\n",
            "Epoch  3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "avg loss so far = 0.014647327337807263: 100%|██████████| 434/434 [08:42<00:00,  1.20s/it]\n",
            "100%|██████████| 63/63 [00:25<00:00,  2.48it/s]\n",
            "  0%|          | 0/434 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0   0.927342  0.918561  0.922931       528\n",
            "           1   0.909853  0.919492  0.914647       472\n",
            "\n",
            "    accuracy                       0.919000      1000\n",
            "   macro avg   0.918598  0.919026  0.918789      1000\n",
            "weighted avg   0.919087  0.919000  0.919021      1000\n",
            "\n",
            "-------------------------------------------------------\n",
            "-------------------------------------------------------\n",
            "-------------------------------------------------------\n",
            "Epoch  4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "avg loss so far = 0.02776819867611576: 100%|██████████| 434/434 [08:41<00:00,  1.20s/it]\n",
            "100%|██████████| 63/63 [00:25<00:00,  2.49it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0   0.894928  0.935606  0.914815       528\n",
            "           1   0.924107  0.877119  0.900000       472\n",
            "\n",
            "    accuracy                       0.908000      1000\n",
            "   macro avg   0.909517  0.906362  0.907407      1000\n",
            "weighted avg   0.908700  0.908000  0.907822      1000\n",
            "\n",
            "-------------------------------------------------------\n",
            "-------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3t69jI2BDa4u"
      },
      "source": [
        "# Model saving / loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EBD_CBUy0JjV"
      },
      "source": [
        "!mkdir \"drive/My Drive/BERT_FINE_TUNING_WNUT/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJ9-7N_Q0izD"
      },
      "source": [
        "path = \"drive/My Drive/BERT_FINE_TUNING_WNUT/CT_2e\"\n",
        "\n",
        "torch.save(model, path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DR0Jri-h0GYS"
      },
      "source": [
        "path = \"drive/My Drive/BERT_FINE_TUNING_WNUT/CT_1e\"\n",
        "\n",
        "model = torch.load(path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kjt2yf_fDdUk"
      },
      "source": [
        "# experiments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k5MK7RLa1a9s"
      },
      "source": [
        "## Training for 1 epoch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "op5HShoxsPwM",
        "outputId": "82ad9174-28e0-4aa1-9c0f-e8966ac5614a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model.train()\n",
        "training_steps = int(len(train_sentences)/batch_size)+1\n",
        "losses = []\n",
        "# 1 epoch over X_train\n",
        "with tqdm(total=training_steps) as progress_bar:\n",
        "  for i in range(0, len(train_sentences), batch_size):\n",
        "    batch_X = train_sentences[i:i+batch_size]\n",
        "    batch_y = torch.LongTensor(y_train[i:i+batch_size]).cuda()\n",
        "\n",
        "\n",
        "    encoding = tokenizer(list(batch_X),padding='max_length',truncation=\"longest_first\", max_length  = max_length,return_tensors='pt')\n",
        "    input_ids = encoding['input_ids'].cuda()\n",
        "    attention_mask = encoding['attention_mask'].cuda()\n",
        "    token_type_ids = encoding['token_type_ids'].cuda()\n",
        "\n",
        "    loss, logits = model(input_ids= input_ids,attention_mask=attention_mask, token_type_ids=token_type_ids,labels=batch_y)\n",
        "\n",
        "\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    model.zero_grad()\n",
        "\n",
        "    losses.append(loss.item())\n",
        "    avg_loss = sum(losses)/len(losses)\n",
        "    progress_bar.update(1)\n",
        "    progress_bar.set_description(\"avg loss so far = {}\".format(avg_loss))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "avg loss so far = 0.06615064456245073: 100%|█████████▉| 867/868 [10:20<00:00,  1.40it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xqnX0_mB1dMh"
      },
      "source": [
        "## Evaluation on the validation set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LZD0-Q931gyN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y6s-IAS9yu68",
        "outputId": "ea2078e1-67d9-47dd-9ec0-b89abec66162",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model.eval()\n",
        "eval_steps = int(len(val_sentences)/batch_size)+1\n",
        "list_of_logits = []\n",
        "\n",
        "with tqdm(total=eval_steps) as progress_bar:\n",
        "  for i in range(0, len(val_sentences), batch_size):\n",
        "    batch_X = val_sentences[i:i+batch_size]\n",
        "\n",
        "\n",
        "\n",
        "    encoding = tokenizer(list(batch_X),padding='max_length',truncation=\"longest_first\", max_length  = max_length,return_tensors='pt')\n",
        "    input_ids = encoding['input_ids'].cuda()\n",
        "    attention_mask = encoding['attention_mask'].cuda()\n",
        "    token_type_ids = encoding['token_type_ids'].cuda()\n",
        "\n",
        "    logits = model(input_ids= input_ids,attention_mask=attention_mask, token_type_ids=token_type_ids)[0]\n",
        "    list_of_logits.extend(logits.tolist())\n",
        "\n",
        "    progress_bar.update(1)\n",
        "    \n",
        "preds_bert = np.argmax(list_of_logits,axis=1)\n",
        "print(classification_report(y_val, preds_bert,digits=6))\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " 99%|█████████▉| 125/126 [00:27<00:00,  4.51it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4dBHilep1kZT"
      },
      "source": [
        "preds_bert = np.argmax(list_of_logits,axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lm8iBJZ75RHR",
        "outputId": "5ea3a4b0-1ea6-44b1-9947-57b7103c6dff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "\n",
        "print(classification_report(y_val, preds_bert,digits=6))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0   0.958150  0.823864  0.885947       528\n",
            "           1   0.829670  0.959746  0.889980       472\n",
            "\n",
            "    accuracy                       0.888000      1000\n",
            "   macro avg   0.893910  0.891805  0.887964      1000\n",
            "weighted avg   0.897507  0.888000  0.887851      1000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pLAgBzvn1-6s",
        "outputId": "2834a0e5-6c18-44d4-fb35-636866af3a3a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "\n",
        "print(classification_report(y_val, preds_bert,digits=6))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0   0.923225  0.910985  0.917064       528\n",
            "           1   0.901879  0.915254  0.908517       472\n",
            "\n",
            "    accuracy                       0.913000      1000\n",
            "   macro avg   0.912552  0.913120  0.912791      1000\n",
            "weighted avg   0.913149  0.913000  0.913030      1000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YetXDf830htC",
        "outputId": "9c7da4ed-5ebe-430f-ac06-453d3f9a9326",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "list_of_logits"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[3.8475430011749268, -3.6093201637268066],\n",
              " [-3.2689993381500244, 2.9922397136688232],\n",
              " [4.415075778961182, -4.092049598693848],\n",
              " [4.124192237854004, -4.193169116973877],\n",
              " [3.827329158782959, -3.527426242828369],\n",
              " [-1.4919925928115845, 0.9087761640548706],\n",
              ".........",
              " [-4.141377925872803, 3.960819721221924]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    }
  ]
}
